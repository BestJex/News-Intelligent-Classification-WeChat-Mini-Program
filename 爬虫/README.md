# 数据爬取

训练新闻分类数据的爬取直接使用 requests 库爬取，BeautifulSoup 解析，存储到 MongoDB 的 news 库中的 train_news 表中。

测试新闻数据的爬取使用 Scrapy 框架爬取，存储到 MongoDB 的 news 库中的 test_news 表中。

## 1、训练新闻分类数据的爬取

**1.1 目标网站**

中国新闻网（静态页面）
域名：http://www.chinanews.com

爬取规则：

滚动新闻：http://域名/scroll-news/年/月日/news.shtml ，例如：http://www.chinanews.com/scroll-news/2018/1207/news.shtml

某个分类下的新闻：http://域名/scroll-news/分类对应的网站文件夹/年/月日/news.shtml，例如：http://www.chinanews.com/scroll-news/mil/2017/1205/news.shtml 为体育分类下的新闻

> 注：分类对应的网站文件夹请以实际名称为准。

**1.2 存储字段**

- 新闻标题
- 新闻分类

**1.3 数据统计**

爬取了 2019.03.06-2012.12.07 的数据，共 3035803 条数据，每个分类下的新闻数量如下：

查询要用到的SQL语句：`db.train_news.aggregate([{$group: {_id: "$news_category", "新闻数量": {$sum: 1}}}, {$sort: {"新闻数量":-1}}])`，分组查询，并按照新闻数量倒序排序。

**1.4 数据处理**

最终新闻分为七大类：

- 国内
- 国际
- 军事
- 体育
- 社会
- 娱乐
- 财经

数据处理后各个分类下的新闻数量如下：



## 2、详细新闻数据的爬取

**2.1 目标网站**

中国新闻网

**2.2 存储字段**

- 新闻标题
- 新闻链接
- 新闻日期时间
- 新闻来源
- 网站上对新闻的分类
- 机器对新闻的分类

> 注意：数据库中的字段还要加上**机器对新闻的分类**这个字段，后面通过机器学习训练好的分类模型来填充该字段。
